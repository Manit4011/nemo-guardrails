{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymongo\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from utils.DocDB import get_conversation_history\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_msg_dataset(df):\n",
    "    user_messages = df[df['role'] == 'user'][['conv_id', 'msg_id', 'time', 'query', 'rewritten_query']]\n",
    "    assistant_responses = df[df['role'] == 'assistant'][['conv_id', 'msg_id', 'response', 'metadata', 'reference']]\n",
    "    assistant_responses['msg_id'] = assistant_responses['msg_id'] - 1\n",
    "    custom_df = pd.merge(user_messages, assistant_responses, on=['conv_id', 'msg_id'], how='left', suffixes=('_user', '_assistant'))\n",
    "    custom_df = custom_df.sort_values(by=['conv_id', 'msg_id'], ascending=[True, True])\n",
    "    return custom_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_users(df):\n",
    "    unique_users = df['conv_id'].nunique()\n",
    "    print(f\"Total unique users: {unique_users}\")\n",
    "    most_frequent_users = df['conv_id'].value_counts().head(5)\n",
    "    # print(most_frequent_users)\n",
    "    return unique_users, most_frequent_users\n",
    "\n",
    "\n",
    "def get_unique_queries(df):\n",
    "    unique_questions = df['query'].nunique()\n",
    "    print(f\"Total unique questions: {unique_questions}\")\n",
    "    most_frequent_questions = df['query'].value_counts().head(5)\n",
    "    # print(most_frequent_questions)\n",
    "    return unique_questions, most_frequent_questions\n",
    "\n",
    "\n",
    "def analyze_conversation_flow(df):\n",
    "    conv_turns = df.groupby('conv_id').size()   # Calculate message count per conversation\n",
    "    avg_turns = round(conv_turns.mean())\n",
    "    # print(f\"Average turns per conversation: {avg_turns}\")\n",
    "    return conv_turns, avg_turns\n",
    "\n",
    "\n",
    "def analyse_user_sentiment(df):\n",
    "    df['sentiment'] = df['query'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    # print(df[['query', 'sentiment']].head(5))\n",
    "    return df['sentiment']\n",
    "\n",
    "\n",
    "def calculate_failure_rate(df):\n",
    "    failed_queries = df[df['response'].isnull()].shape[0]\n",
    "    total_queries = df.shape[0]\n",
    "    failure_rate = failed_queries / total_queries\n",
    "    return failure_rate\n",
    "\n",
    "\n",
    "def get_response_accuracy(df):\n",
    "    def calculate_accuracy(row):\n",
    "        if pd.isna(row['response']) and not pd.isna(row['ground_truth_response']):\n",
    "            return 0\n",
    "        elif isinstance(row['response'], str) and row['response'] in row['ground_truth_response']:\n",
    "            return 1\n",
    "        elif isinstance(row['response'], str) and row['response'] and row['ground_truth_response'] and \\\n",
    "             any(word in row['ground_truth_response'] for word in row['response'].split()):\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0\n",
    "    df['response_accuracy'] = df.apply(calculate_accuracy, axis=1)\n",
    "    accuracy = df['response_accuracy'].mean()\n",
    "    return df['response_accuracy'], accuracy\n",
    "\n",
    "\n",
    "def get_rewrite_accuracy(df):\n",
    "    # Assuming you have a column 'correct_intent' with labeled intents\n",
    "    df['intent_accuracy'] = df.apply(lambda x: 1 if x['query'] in x['rewritten_query'] else 0, axis=1)\n",
    "    intent_accuracy = df['intent_accuracy'].mean()\n",
    "    print(f\"Intent recognition accuracy: {intent_accuracy}\")\n",
    "    return intent_accuracy\n",
    "\n",
    "\n",
    "def analyze_session(df):\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    session_length = df.groupby('conv_id')['time'].apply(lambda x: x.max() - x.min())\n",
    "    # print(f\"Session length (time difference between first and last message):{session_length}\")\n",
    "    return session_length\n",
    "\n",
    "\n",
    "def extract_top_keywords(df):\n",
    "    vectorizer = CountVectorizer(max_features=10, stop_words='english')\n",
    "    X = vectorizer.fit_transform(df['query'])\n",
    "    keywords = vectorizer.get_feature_names_out()\n",
    "    # print(f\"Top keywords: {keywords}\")\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bedrock_call import get_prompt\n",
    "from docdbVS import similarity_search\n",
    "from app import create_embeddings, call_llm\n",
    "\n",
    "def clean_raw_response(raw_response):\n",
    "    try:\n",
    "        cleaned_response = raw_response.strip()\n",
    "        if cleaned_response.startswith('\"\"\"') and cleaned_response.endswith('\"\"\"'):\n",
    "            cleaned_response = cleaned_response.strip('\"\"\"')\n",
    "            response = json.loads(cleaned_response)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        prompt = f\"You need to correct the JSON format of this raw_response to be parsed successfully. raw_response:{raw_response}\"\n",
    "        response = call_llm(client, prompt)\n",
    "        return response\n",
    "\n",
    "def create_ground_truth(db, unique_questions):\n",
    "    ground_truth_responses = []\n",
    "    ground_truth_metadata = []\n",
    "    ground_truth_references = []\n",
    "\n",
    "    for rewritten_query in unique_questions:\n",
    "        try:\n",
    "            client = boto3.client(service_name='bedrock-runtime', region_name=\"ap-south-1\")\n",
    "            embed_client = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\")\n",
    "            print(\"Creating embeddings for the query.\")\n",
    "            query_embedding = create_embeddings(embed_client, rewritten_query)\n",
    "\n",
    "            if query_embedding is None:\n",
    "                print(\"Error: Failed to create embeddings for the query.\")\n",
    "                ground_truth_responses.append(None)\n",
    "                ground_truth_metadata.append(None)\n",
    "                ground_truth_references.append(None)\n",
    "                continue\n",
    "\n",
    "            similar_docs = similarity_search(db['Test'], embedding=query_embedding, embedding_key='embedding', text_key='text', k=5)\n",
    "            prompt = get_prompt(rewritten_query, similar_docs, None)\n",
    "            response = call_llm(client, prompt, model='meta.llama3-70b-instruct-v1:0')\n",
    "\n",
    "            if response is None:\n",
    "                print(\"Error: Failed to generate a response from LLM.\")\n",
    "                ground_truth_responses.append(None)\n",
    "                ground_truth_metadata.append(None)\n",
    "                ground_truth_references.append(None)\n",
    "                continue  # Skip this iteration\n",
    "\n",
    "            # Parse the response and validate the structure\n",
    "            try:\n",
    "                parsed_response = json.loads(response)\n",
    "                print(\"LLM response parsed successfully.\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error: JSONDecodeError occurred. Attempting to clean response.\")\n",
    "                result = clean_raw_response(response)\n",
    "                try:\n",
    "                    parsed_response = json.loads(result)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error: Failed to parse LLM response: {e}\")\n",
    "                    ground_truth_responses.append(None)\n",
    "                    ground_truth_metadata.append(None)\n",
    "                    ground_truth_references.append(None)\n",
    "                    continue  # Skip this iteration\n",
    "\n",
    "            # Append parsed response data\n",
    "            ground_truth_responses.append(parsed_response.get('Answer'))\n",
    "            ground_truth_metadata.append(parsed_response.get('Metadata'))\n",
    "            ground_truth_references.append(parsed_response.get('References'))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: Unexpected error in create_ground_truth: {e}\")\n",
    "            ground_truth_responses.append(None)\n",
    "            ground_truth_metadata.append(None)\n",
    "            ground_truth_references.append(None)\n",
    "\n",
    "    # Create a DataFrame to hold the ground truth responses for unique questions\n",
    "    results_df = pd.DataFrame({\n",
    "        'rewritten_query': unique_questions,\n",
    "        'ground_truth_response': ground_truth_responses,\n",
    "        'ground_truth_metadata': ground_truth_metadata,\n",
    "        'ground_truth_reference': ground_truth_references\n",
    "    })\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pymongo.client:You appear to be connected to a DocumentDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/documentdb\n"
     ]
    }
   ],
   "source": [
    "# Fetch and analyze data\n",
    "df = get_conversation_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_prompt(row):\n",
    "    prompt = f\"\"\"\n",
    "Evaluate the following response based on these metrics: faithfulness, context precision, answer correctness, answer relevancy, and context recall.\n",
    "\n",
    "**Question:** {row['rewritten_query']}\n",
    "**Response:** {row['response']}\n",
    "**Ground Truth:** {row['ground_truth_response']}\n",
    "**Contexts:** {row['ground_truth_reference'] if row['ground_truth_reference'] else \"No context available.\"}\n",
    "\n",
    "Please provide scores for each metric in JSON format as shown below:\n",
    "{{\n",
    "    \"Faithfulness\": \"<Score between 0 and 1>\",\n",
    "    \"Context_precision\": \"<Score between 0 and 1>\",\n",
    "    \"Answer_correctness\": \"<Score between 0 and 1>\",\n",
    "    \"Answer_relevancy\": \"<Score between 0 and 1>\",\n",
    "    \"Context_recall\": \"<Score between 0 and 1>\",\n",
    "    \"Reason\": \"<Brief explanation (max 20 words)>\"\n",
    "}}\n",
    "\n",
    "Return only the output JSON without any additional text.\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ragas_analysis(df):\n",
    "    df['response'].fillna(\"\", inplace=True)  # Avoid chaining warnings\n",
    "    scores = { \n",
    "        'faithfulness': [], \n",
    "        'context_precision': [], \n",
    "        'answer_correctness': [], \n",
    "        'answer_relevancy': [], \n",
    "        'context_recall': [], \n",
    "        'reason': []\n",
    "    }\n",
    "    for index, row in df.iterrows():\n",
    "        client = boto3.client(service_name='bedrock-runtime', region_name=\"ap-south-1\")\n",
    "        eval_prompt = get_eval_prompt(row)\n",
    "        scores_response = call_llm(client, eval_prompt, model='meta.llama3-70b-instruct-v1:0')\n",
    "        print(scores_response)\n",
    "        # Handle possible JSON response\n",
    "        try:\n",
    "            evaluation_scores = json.loads(scores_response)\n",
    "            print(evaluation_scores)\n",
    "            for key in scores.keys():\n",
    "                print(key)\n",
    "                scores[key].append(evaluation_scores.get(key.capitalize(), None))\n",
    "                print(evaluation_scores.get(key.capitalize()))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Failed to parse evaluation scores for index {index}\")\n",
    "    for key, value in scores.items():\n",
    "        df[key] = value\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_history(db, df=None, file_name=None, save_file=\"analysis_report.xlsx\"):\n",
    "    if file_name:\n",
    "        df = pd.read_excel(file_name)\n",
    "\n",
    "    # Perform analysis\n",
    "    unique_users, most_frequent_users = get_unique_users(df)\n",
    "    unique_questions, most_frequent_questions = get_unique_queries(df)\n",
    "    conv_size, avg_conv_size = analyze_conversation_flow(df)\n",
    "    df['sentiment'] = analyse_user_sentiment(df)\n",
    "    session_length = analyze_session(df)\n",
    "    most_inquired_topics = extract_top_keywords(df)\n",
    "\n",
    "    # Most asked unique questions\n",
    "    top_questions = df['rewritten_query'].value_counts().head(20).index.tolist()    \n",
    "    ground_truth_df = create_ground_truth(db, top_questions)\n",
    "\n",
    "    # Filter and merge\n",
    "    custom_df = df[df['rewritten_query'].isin(top_questions)].copy()\n",
    "    custom_df = custom_df.merge(ground_truth_df, on='rewritten_query', how='left')\n",
    "    custom_df = custom_df.drop_duplicates(subset='rewritten_query')\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    failure_rate = calculate_failure_rate(df)\n",
    "    rewrite_accuracy = get_rewrite_accuracy(df)\n",
    "    custom_df['response_accuracy'], avg_accuracy = get_response_accuracy(custom_df)\n",
    "\n",
    "    print(custom_df['response_accuracy'])\n",
    "    custom_df = ragas_analysis(custom_df)\n",
    "    print(custom_df)\n",
    "    \n",
    "    # Check if the file already exists and Save analysis results to an Excel file\n",
    "    if not os.path.exists(save_file):\n",
    "        with pd.ExcelWriter(save_file, engine='openpyxl', mode='w') as writer:\n",
    "            df.to_excel(writer, sheet_name='Data w sentiment analysis', index=False)\n",
    "    else:\n",
    "        with pd.ExcelWriter(save_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "            df.to_excel(writer, sheet_name='Data w sentiment analysis', index=False)\n",
    "    with pd.ExcelWriter(save_file, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "        custom_df.to_excel(writer, sheet_name='Data w Ground Truth', index=False)\n",
    "        # Save user analysis\n",
    "        user_data = most_frequent_users.reset_index().rename(columns={'conv_id': 'User', 'count': 'Count'})\n",
    "        user_data.to_excel(writer, sheet_name='User Analysis', index=False)\n",
    "        \n",
    "        # Save query analysis\n",
    "        query_data = most_frequent_questions.reset_index().rename(columns={'query': 'Query', 'count': 'Count'})\n",
    "        query_data.to_excel(writer, sheet_name='Query Analysis', index=False)\n",
    "        \n",
    "        # Save conversation flow analysis\n",
    "        combined_data = pd.DataFrame({\n",
    "            'conv_id': conv_size.index,\n",
    "            'Interaction Count': conv_size.values,\n",
    "            'Session Length': session_length.values\n",
    "        })\n",
    "        combined_data.to_excel(writer, sheet_name='Conversation Analysis', index=False)\n",
    "\n",
    "        # Save keywords\n",
    "        keywords_data = pd.DataFrame(most_inquired_topics, columns=['Keyword'])\n",
    "        keywords_data.to_excel(writer, sheet_name='Top Keywords', index=False)\n",
    "\n",
    "        # Save failure rate and accuracy\n",
    "        summary = pd.DataFrame({\n",
    "            'Metric': ['Failure Rate', 'Rewrite Accuracy', 'Response Accuracy'],\n",
    "            'Value': [failure_rate, rewrite_accuracy, avg_accuracy]\n",
    "        })\n",
    "        summary.to_excel(writer, sheet_name='Summary', index=False)\n",
    "\n",
    "    print(f\"Analysis successfully saved to {save_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to conversation_data.xlsx\n",
      "Data successfully saved to conv_history.xlsx\n",
      "Total unique users: 24\n",
      "Total unique questions: 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: ACCESS_TO_AWS_SERVICES\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '982d7b3e-d5ab-4e55-8b03-b52424bfe275', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:12:42 GMT', 'content-type': 'application/json', 'content-length': '646', 'connection': 'keep-alive', 'x-amzn-requestid': '982d7b3e-d5ab-4e55-8b03-b52424bfe275', 'x-amzn-bedrock-invocation-latency': '1861', 'x-amzn-bedrock-output-token-count': '111', 'x-amzn-bedrock-input-token-count': '1205'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab45de0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The number of leaves in Gemini Solutions is not explicitly mentioned in the provided texts. However, according to the company's policies, employees are entitled to a certain number of leaves. Unfortunately, the exact number is not specified in the given texts.\\\",\\n    \\\"References\\\": [],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"How many leaves are there in gemini solutions?\\\",\\n        \\\"source\\\": \\\"Gemini Solutions Policy Documents\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":1205,\"generation_token_count\":111,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'b687a0fa-a60e-44af-8a80-86ed59ec3d8e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:12:45 GMT', 'content-type': 'application/json', 'content-length': '498', 'connection': 'keep-alive', 'x-amzn-requestid': 'b687a0fa-a60e-44af-8a80-86ed59ec3d8e', 'x-amzn-bedrock-invocation-latency': '1594', 'x-amzn-bedrock-output-token-count': '95', 'x-amzn-bedrock-input-token-count': '819'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab47880>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Hi! I'm Jinie, your HR policy bot. I'm here to help you with any questions or concerns you may have regarding Gemini Solutions' company policies. Please feel free to ask me anything!\\\",\\n    \\\"References\\\": [],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"hi jinie\\\",\\n        \\\"source\\\": \\\"N/A\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":819,\"generation_token_count\":95,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '0434e442-8159-4776-a06a-9e946f903db0', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:12:48 GMT', 'content-type': 'application/json', 'content-length': '466', 'connection': 'keep-alive', 'x-amzn-requestid': '0434e442-8159-4776-a06a-9e946f903db0', 'x-amzn-bedrock-invocation-latency': '1468', 'x-amzn-bedrock-output-token-count': '88', 'x-amzn-bedrock-input-token-count': '676'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab445e0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Hello! I'm Jinie, the HR policy bot for Gemini Solutions. I'm here to help you with any company policy-related queries. Please feel free to ask me anything!\\\",\\n    \\\"References\\\": [],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"hi\\\",\\n        \\\"source\\\": \\\"N/A\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":676,\"generation_token_count\":88,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '13b8febf-71d4-4064-a4cb-890972e7e5c3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:12:53 GMT', 'content-type': 'application/json', 'content-length': '1073', 'connection': 'keep-alive', 'x-amzn-requestid': '13b8febf-71d4-4064-a4cb-890972e7e5c3', 'x-amzn-bedrock-invocation-latency': '3534', 'x-amzn-bedrock-output-token-count': '226', 'x-amzn-bedrock-input-token-count': '856'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab36950>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"To download your payslips, follow these steps: * Log in to your GreytHR account * Navigate to the payslips section * View and download your monthly payslips\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"You can log in to your GreytHR account, navigate to your payslips section to view your monthly payslips there.\\\",\\n            \\\"source\\\": \\\"Accounts - Remuneration.csv - Sheet1 - 43\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"As mentioned during your induction, please visit the Accounts portal tab on MIS, it will further lead you to GreytHR portal. You can view/ download payslips from there.\\\",\\n            \\\"source\\\": \\\"HR - Onboarding Portal.csv - Sheet1 - 15\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What are the steps to download my payslips?\\\",\\n        \\\"source\\\": \\\"HR - Onboarding Portal.csv\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":856,\"generation_token_count\":226,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '0bffdc9f-c1c7-4458-8504-0539485123c4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:12:56 GMT', 'content-type': 'application/json', 'content-length': '498', 'connection': 'keep-alive', 'x-amzn-requestid': '0bffdc9f-c1c7-4458-8504-0539485123c4', 'x-amzn-bedrock-invocation-latency': '1590', 'x-amzn-bedrock-output-token-count': '95', 'x-amzn-bedrock-input-token-count': '798'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab44c70>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Hi! I'm Jinie, your HR policy bot. I'm here to help you with any questions or concerns you may have regarding Gemini Solutions' company policies. Please feel free to ask me anything!\\\",\\n    \\\"References\\\": [],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"Hi Jinie\\\",\\n        \\\"source\\\": \\\"N/A\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":798,\"generation_token_count\":95,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '4ced468f-241e-4f59-a886-bc7db422485c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:00 GMT', 'content-type': 'application/json', 'content-length': '879', 'connection': 'keep-alive', 'x-amzn-requestid': '4ced468f-241e-4f59-a886-bc7db422485c', 'x-amzn-bedrock-invocation-latency': '3349', 'x-amzn-bedrock-output-token-count': '212', 'x-amzn-bedrock-input-token-count': '873'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cabc2dd0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Each year, you'll receive 7 Casual Leaves (CLs), 7 Sick Leaves (SLs) credited annually and 1.5 Privilege Leaves (PLs) on a monthly basis. This means you can take a total of 14 leaves (7 CLs + 7 SLs) annually, plus 18 PLs (1.5/month * 12 months).\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"Each year, you’ll receive 7 Casual Leaves (CLs), 7 Sick Leaves (SLs) credited annually and 1.5 Privilege Leaves (PLs) on monthly basis.\\\",\\n            \\\"source\\\": \\\"HR - Leave Policy.csv - Sheet1 - Index 6\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"How many leaves can we take in a year.\\\",\\n        \\\"source\\\": \\\"HR - Leave Policy.csv\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":873,\"generation_token_count\":212,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '5c9580f1-600c-44d4-a89a-5f1ab654f2ae', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:07 GMT', 'content-type': 'application/json', 'content-length': '1703', 'connection': 'keep-alive', 'x-amzn-requestid': '5c9580f1-600c-44d4-a89a-5f1ab654f2ae', 'x-amzn-bedrock-invocation-latency': '5312', 'x-amzn-bedrock-output-token-count': '341', 'x-amzn-bedrock-input-token-count': '1020'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab46080>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The terms on which the appraisal amount depends are not explicitly stated in the provided texts. However, it can be inferred that the appraisal cycle, employee transfer, and notice period may influence the appraisal amount. * The appraisal cycle runs from April 1st to March 31st of the financial year. * Employees who transfer after September 30th will not be eligible for an appraisal within the same calendar year, and appraisals will be conducted on a prorated basis in the subsequent year if the employee has a minimum of six months of employment in the home country by March 31st. * Serving a notice period does not qualify an employee for an appraisal.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"The appraisal cycle runs from April 1st to March 31st of the financial year.\\\",\\n            \\\"source\\\": \\\"ITAdmin - Misscellaneous.csv - Sheet1 - 23\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Employees who transfer after September 30th will not be eligible for an appraisal within the same calendar year.\\\",\\n            \\\"source\\\": \\\"Travel Policy.csv - Sheet1 - 33\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Will I be considered for appraisal if I am serving notice period? Answer: No.\\\",\\n            \\\"source\\\": \\\"HR - Exit Policy.csv - Sheet1 - 13\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What are the terms on which it depends how much the appraisal will be?\\\",\\n        \\\"source\\\": \\\"ITAdmin - Misscellaneous.csv\\\",\\n        \\\"response_length\\\": \\\"176\\\"\\n    }\\n}\",\"prompt_token_count\":1020,\"generation_token_count\":341,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'f5ec2f71-67a1-4d26-abb8-bc144111e214', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:13 GMT', 'content-type': 'application/json', 'content-length': '1559', 'connection': 'keep-alive', 'x-amzn-requestid': 'f5ec2f71-67a1-4d26-abb8-bc144111e214', 'x-amzn-bedrock-invocation-latency': '4600', 'x-amzn-bedrock-output-token-count': '295', 'x-amzn-bedrock-input-token-count': '1153'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab51930>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The POSH (Prevention of Sexual Harassment) policy of Gemini Solutions is intended to ensure an environment that is free from any form of harassment or unlawful discrimination and the dignity of each employee is respected and promoted. This policy applies to all associates of Gemini Solutions (permanent, contractual, and academic interns) and is not restricted to the workspace, but also applicable in client/vendor location, social gatherings, functions, events, and while travel.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"The policy is intended to ensure an environment that is free from any form of harassment or unlawful discrimination and the dignity of each employee is respected and promoted.\\\",\\n            \\\"source\\\": \\\"SEXUAL HARRASMENT POLICY Updated_India.pdf - 4\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"This policy applies to all the associates of Gemini Solutions (permanent, contractual, and academic interns) and is not restricted to the workspace, its applicable in client/vendor location, social gatherings, functions, events, and while travel.\\\",\\n            \\\"source\\\": \\\"SEXUAL HARRASMENT POLICY Updated_India.pdf - 4\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"what is the posh harassment policy ?\\\",\\n        \\\"source\\\": \\\"SEXUAL HARRASMENT POLICY Updated_India.pdf\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":1153,\"generation_token_count\":295,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '4ecd7eca-9b46-43da-9625-e4c3c2af9903', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:17 GMT', 'content-type': 'application/json', 'content-length': '943', 'connection': 'keep-alive', 'x-amzn-requestid': '4ecd7eca-9b46-43da-9625-e4c3c2af9903', 'x-amzn-bedrock-invocation-latency': '2951', 'x-amzn-bedrock-output-token-count': '183', 'x-amzn-bedrock-input-token-count': '1145'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab377f0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The BC/DR Leader is responsible for overseeing the smooth transition from primary center to the secondary center.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"To oversee the smooth transition from primary center to the secondary center\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 22\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"IT Head at Recovery Site - Oversee the smooth transition process\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 23\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"Who is responsible for overseeing the smooth transition from primary center to the secondary center?\\\",\\n        \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":1145,\"generation_token_count\":183,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '93772b5f-05ab-4bd4-91e4-4e4dec105bd9', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:24 GMT', 'content-type': 'application/json', 'content-length': '1677', 'connection': 'keep-alive', 'x-amzn-requestid': '93772b5f-05ab-4bd4-91e4-4e4dec105bd9', 'x-amzn-bedrock-invocation-latency': '4999', 'x-amzn-bedrock-output-token-count': '318', 'x-amzn-bedrock-input-token-count': '1184'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab46920>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Yes, sabotage or vandalism to building, computer equipment, and local communication facilities can be prevented by people and staff being aware of suspicious activities/items and regular monitoring of visitors inside the building. This is ensured through various measures such as * background checks on all prospective employees, * restricted access to critical IT equipment, * regular monitoring of visitors, * security guards manning the site 24x7, and * security cameras monitoring the premises.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"Background checks are performed on all prospective employees.\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 18\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Access to all critical IT equipment is restricted to named users\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 18\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"The site is manned 24x7 by security guards as well as monitored by security cameras to prevent theft of equipment\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 18\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"Can sabotage or vandalism to building, computer equipment, and local communication facilities be prevented by people and staff being aware of suspicious activities/items and regular monitoring of visitors inside the building?\\\",\\n        \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf\\\",\\n        \\\"response_length\\\": \\\"106\\\"\\n    }\\n}\",\"prompt_token_count\":1184,\"generation_token_count\":318,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '460960a2-5a4d-4823-9b49-188f5bfb5924', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:30 GMT', 'content-type': 'application/json', 'content-length': '1531', 'connection': 'keep-alive', 'x-amzn-requestid': '460960a2-5a4d-4823-9b49-188f5bfb5924', 'x-amzn-bedrock-invocation-latency': '5041', 'x-amzn-bedrock-output-token-count': '325', 'x-amzn-bedrock-input-token-count': '1073'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab44490>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Gemini Solutions' maternity leave policy allows married female employees to enjoy up to 26 weeks of paid maternity leave. This can be up to 8 weeks before the due date and 18 weeks after the baby arrives. For moms with more than two children, the paid leave is 12 weeks (6 weeks before and 6 weeks after delivery). To be eligible, the employee must have worked at least 80 continuous days.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"If you're a married female employee, you can enjoy up to 26 weeks of paid maternity leave.\\\",\\n            \\\"source\\\": \\\"HR - Leave Policy.csv - Sheet1 - 22\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"A married female employee will be granted a paid maternity leave up to a maximum of 26 consecutive weeks as required by the relevant legislation's applicable, or in force.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - 5\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"At least 80 days of continuous employment should have been spent in the organization to avail the benefit.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - 6\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"what is the maternity leave policy ?\\\",\\n        \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":1073,\"generation_token_count\":325,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '2a288f43-07cb-44ad-b251-9a2807c24f47', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:36 GMT', 'content-type': 'application/json', 'content-length': '1410', 'connection': 'keep-alive', 'x-amzn-requestid': '2a288f43-07cb-44ad-b251-9a2807c24f47', 'x-amzn-bedrock-invocation-latency': '4254', 'x-amzn-bedrock-output-token-count': '271', 'x-amzn-bedrock-input-token-count': '1221'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab52980>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The Buddy Program is an integral part of the organization's orientation program for new employees, aimed at helping them quickly settle into the environment and integrate with the organization's culture, attitude, and expectations. The program provides a point of contact for general queries regarding day-to-day operational issues and is coordinated by the HR department.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"5.1 The Buddy Program is an integral part of the organization's orientation program for new employees and to assist new employees in the early period of their careers.\\\",\\n            \\\"source\\\": \\\"Gemini-BUDDY PROGRAM_Version1.0_India.pdf - 4\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"6.1 To provide the new employee with a point of contact for general queries regarding day-to-day operational issues, (such as the location of facilities, information processing requirements, and relevant organization policies).\\\",\\n            \\\"source\\\": \\\"Gemini-BUDDY PROGRAM_Version1.0_India.pdf - 5\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"what is the buddy program ?\\\",\\n        \\\"source\\\": \\\"Gemini-BUDDY PROGRAM_Version1.0_India.pdf\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":1221,\"generation_token_count\":271,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'ac59408d-c67a-46a5-b2dd-17358c2fad21', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:41 GMT', 'content-type': 'application/json', 'content-length': '1168', 'connection': 'keep-alive', 'x-amzn-requestid': 'ac59408d-c67a-46a5-b2dd-17358c2fad21', 'x-amzn-bedrock-invocation-latency': '3694', 'x-amzn-bedrock-output-token-count': '232', 'x-amzn-bedrock-input-token-count': '1091'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab34400>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"In case of loss or theft of equipment or data, the following individuals should be immediately notified: * Immediate supervisor, * Admin, and * IT department.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"In case of Laptop immediately report the incident to your immediate supervisor, Admin, and IT department\\\",\\n            \\\"source\\\": \\\"Gemini - Asset Management Policy and Procedure v1.9_India.pdf - Page 5\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"If an employee's computing device be lost or stolen, the employee MUST: (i) Immediately report the incident to his/her immediate supervisor, Admin, and IT department;\\\",\\n            \\\"source\\\": \\\"Geimini - E POLICY V1.6_India.pdf - Page 6\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"Who should be immediately notified in case of loss or theft of equipment or data?\\\",\\n        \\\"source\\\": \\\"Gemini - Asset Management Policy and Procedure v1.9_India.pdf\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":1091,\"generation_token_count\":232,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '7339479d-11b6-4269-93dc-8b6883081ca2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:44 GMT', 'content-type': 'application/json', 'content-length': '529', 'connection': 'keep-alive', 'x-amzn-requestid': '7339479d-11b6-4269-93dc-8b6883081ca2', 'x-amzn-bedrock-invocation-latency': '1765', 'x-amzn-bedrock-output-token-count': '106', 'x-amzn-bedrock-input-token-count': '1012'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab46a70>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Hi! I'm Jinie, your HR policy bot. I'm here to help you with any questions or concerns you may have regarding Gemini Solutions' company policies. Please feel free to ask me anything!\\\",\\n    \\\"References\\\": [],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"<at>jinie by gemini-dev</at> hi jinie\\\",\\n        \\\"source\\\": \\\"N/A\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":1012,\"generation_token_count\":106,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'e06b30fb-4301-4de9-8239-02d4c6a1d3f3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:48 GMT', 'content-type': 'application/json', 'content-length': '848', 'connection': 'keep-alive', 'x-amzn-requestid': 'e06b30fb-4301-4de9-8239-02d4c6a1d3f3', 'x-amzn-bedrock-invocation-latency': '2697', 'x-amzn-bedrock-output-token-count': '165', 'x-amzn-bedrock-input-token-count': '1136'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2ea10>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"In case of a power outage during off-office hours, it is the duty of the full-time caretakers or security guards to report the outage immediately.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"During off office hours, Concerned person checks the power source and reports any power outage immediately to any member of the full time caretaker / security guard.\\\",\\n            \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf - Page 19\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"Who is responsible for reporting a power outage during off-office hours?\\\",\\n        \\\"source\\\": \\\"BC _ DR plans V1.4_India.pdf\\\",\\n        \\\"response_length\\\": \\\"56\\\"\\n    }\\n}\",\"prompt_token_count\":1136,\"generation_token_count\":165,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'bebc7c2a-3d49-43c3-ba85-238938e434b7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:52 GMT', 'content-type': 'application/json', 'content-length': '708', 'connection': 'keep-alive', 'x-amzn-requestid': 'bebc7c2a-3d49-43c3-ba85-238938e434b7', 'x-amzn-bedrock-invocation-latency': '2481', 'x-amzn-bedrock-output-token-count': '153', 'x-amzn-bedrock-input-token-count': '962'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab35f90>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Pluxee is a food wallet provided by Gemini Solutions, where INR 2000 is credited every month if you opt for it.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"If you opt for it, INR 2000 will be credited to your Sodexo (Pluxee) food wallet every month.\\\",\\n            \\\"source\\\": \\\"Accounts - Remuneration.csv - Sheet1 - 12\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"what is pluxee or how does pluxee work\\\",\\n        \\\"source\\\": \\\"Accounts - Remuneration.csv\\\",\\n        \\\"response_length\\\": \\\"36\\\"\\n    }\\n}\",\"prompt_token_count\":962,\"generation_token_count\":153,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'b80e7128-f496-4eff-889f-6e2a690f2052', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:13:58 GMT', 'content-type': 'application/json', 'content-length': '1421', 'connection': 'keep-alive', 'x-amzn-requestid': 'b80e7128-f496-4eff-889f-6e2a690f2052', 'x-amzn-bedrock-invocation-latency': '4274', 'x-amzn-bedrock-output-token-count': '267', 'x-amzn-bedrock-input-token-count': '1168'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2ec50>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"Gemini Solutions has a travel policy in place that outlines the guidelines and procedures for business travel. The policy covers various aspects of travel, including transportation, accommodation, and local transportation expenses. It's essential to book trips at least two weeks in advance, unless it's an unforeseen trip, and obtain approval from your Reporting Head. Additionally, the policy specifies non-reimbursable expenses, such as personal entertainment, first-class airfare, and tips for porters, bellhops, and maid service.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"Your trip must be booked at least [two weeks] in advance unless it's an unforeseen trip.\\\",\\n            \\\"source\\\": \\\"Intra Country Travel Policy 1.pdf - Page 5\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Travel expenses incurred for personal convenience or preference, or otherwise not required to fulfill the business purpose of the travel.\\\",\\n            \\\"source\\\": \\\"Domestic Travel Policy - Final.pdf - Page 7\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What about travel?\\\",\\n        \\\"source\\\": \\\"Intra Country Travel Policy 1.pdf and Domestic Travel Policy - Final.pdf\\\",\\n        \\\"response_length\\\": \\\"156\\\"\\n    }\\n}\",\"prompt_token_count\":1168,\"generation_token_count\":267,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'd34b97a7-3dd2-439d-a374-646e8271fe34', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:05 GMT', 'content-type': 'application/json', 'content-length': '1809', 'connection': 'keep-alive', 'x-amzn-requestid': 'd34b97a7-3dd2-439d-a374-646e8271fe34', 'x-amzn-bedrock-invocation-latency': '6139', 'x-amzn-bedrock-output-token-count': '397', 'x-amzn-bedrock-input-token-count': '1072'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab45660>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"If you're a married female employee, you can enjoy up to 26 weeks of paid maternity leave. This can be up to 8 weeks before your due date and 18 weeks after your baby arrives. For moms with more than two children, the paid leave is 12 weeks (6 weeks before and 6 weeks after delivery). Just make sure you've worked at least 80 continuous days to be eligible. * You can avail this benefit up to two times during your employment.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"If you're a married female employee, you can enjoy up to 26 weeks of paid maternity leave.\\\",\\n            \\\"source\\\": \\\"HR - Leave Policy.csv - Sheet1 - 22\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"A married female employee will be granted a paid maternity leave up to a maximum of 26 consecutive weeks as required by the relevant legislation's applicable, or in force.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - 5\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"5.3.2 At least 80 days of continuous employment should have been spent in the organization to avail the benefit.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - 6\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"5.3.1 Only two times during the employment, the employee is permissible to avail the Maternity benefit.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - 6\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What is the maternal leave policy?\\\",\\n        \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf\\\",\\n        \\\"response_length\\\": \\\"156\\\"\\n    }\\n}\",\"prompt_token_count\":1072,\"generation_token_count\":397,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '793f3863-b848-4715-aa1e-2d91125f990c', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:10 GMT', 'content-type': 'application/json', 'content-length': '995', 'connection': 'keep-alive', 'x-amzn-requestid': '793f3863-b848-4715-aa1e-2d91125f990c', 'x-amzn-bedrock-invocation-latency': '3517', 'x-amzn-bedrock-output-token-count': '220', 'x-amzn-bedrock-input-token-count': '1214'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2c310>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The types of leaves mentioned in Gemini Solutions' Leave Policy Version 5.0 are: * Casual Leave, * Sick Leave, * Leave Without Pay, and * Emergency Leave.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"5. Types of Leaves\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - Page 3\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"5.2 Sick Leaves: Every confirmed employee will be allowed 7 days of sick leave on full fixed pay in one leave year.\\\",\\n            \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf - Page 5\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What types of leaves are mentioned in Gemini Solutions' Leave Policy Version 5.0?\\\",\\n        \\\"source\\\": \\\"Gemini-LEAVE POLICY_Version 5.0_India.pdf\\\",\\n        \\\"response_length\\\": \\\"76\\\"\\n    }\\n}\",\"prompt_token_count\":1214,\"generation_token_count\":220,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Creating embeddings for the query.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n",
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '30b6c2da-ab59-42a6-b58b-8d6f0750f957', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:16 GMT', 'content-type': 'application/json', 'content-length': '1536', 'connection': 'keep-alive', 'x-amzn-requestid': '30b6c2da-ab59-42a6-b58b-8d6f0750f957', 'x-amzn-bedrock-invocation-latency': '4721', 'x-amzn-bedrock-output-token-count': '302', 'x-amzn-bedrock-input-token-count': '1022'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2dbd0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Answer\\\": \\\"The terms on which the appraisal amount depends are not explicitly stated in the provided texts. However, it can be inferred that the appraisal cycle, employee transfer, and notice period may influence the appraisal amount. * The appraisal cycle runs from April 1st to March 31st of the financial year. * Employees who transfer after September 30th will not be eligible for an appraisal within the same calendar year. * Employees serving notice period will not be considered for appraisal.\\\",\\n    \\\"References\\\": [\\n        {\\n            \\\"Statement\\\": \\\"The appraisal cycle runs from April 1st to March 31st of the financial year.\\\",\\n            \\\"source\\\": \\\"ITAdmin - Misscellaneous.csv - Sheet1 - 23\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Employees who transfer after September 30th will not be eligible for an appraisal within the same calendar year.\\\",\\n            \\\"source\\\": \\\"Travel Policy.csv - Sheet1 - 33\\\"\\n        },\\n        {\\n            \\\"Statement\\\": \\\"Will I be considered for appraisal if I am serving notice period? Answer: No.\\\",\\n            \\\"source\\\": \\\"HR - Exit Policy.csv - Sheet1 - 13\\\"\\n        }\\n    ],\\n    \\\"Metadata\\\": {\\n        \\\"conversation_id\\\": \\\"None\\\",\\n        \\\"query\\\": \\\"What are the terms on which it depends how much the appraisal it will be?\\\",\\n        \\\"source\\\": \\\"ITAdmin - Misscellaneous.csv\\\",\\n        \\\"response_length\\\": \\\"176\\\"\\n    }\\n}\",\"prompt_token_count\":1022,\"generation_token_count\":302,\"stop_reason\":\"stop\"}\n",
      "/tmp/ipykernel_1203348/1905006962.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['response'].fillna(\"\", inplace=True)  # Avoid chaining warnings\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM response parsed successfully.\n",
      "Intent recognition accuracy: 0.5487804878048781\n",
      "0      0.5\n",
      "1      1.0\n",
      "2      0.5\n",
      "3      0.5\n",
      "4      0.5\n",
      "16     0.5\n",
      "20     0.0\n",
      "50     0.5\n",
      "71     0.5\n",
      "72     0.5\n",
      "100    0.0\n",
      "108    0.0\n",
      "114    0.0\n",
      "120    0.5\n",
      "124    0.0\n",
      "125    0.5\n",
      "128    0.5\n",
      "133    0.0\n",
      "144    0.0\n",
      "157    0.5\n",
      "Name: response_accuracy, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'c40e5e86-6010-4097-bdce-f79c3612f06b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:17 GMT', 'content-type': 'application/json', 'content-length': '356', 'connection': 'keep-alive', 'x-amzn-requestid': 'c40e5e86-6010-4097-bdce-f79c3612f06b', 'x-amzn-bedrock-invocation-latency': '1140', 'x-amzn-bedrock-output-token-count': '70', 'x-amzn-bedrock-input-token-count': '400'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab37040>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"0.8\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"0.8\\\",\\n    \\\"Reason\\\": \\\"Response accurately summarizes the steps to download payslips.\\\"\\n}\",\"prompt_token_count\":400,\"generation_token_count\":70,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"0.8\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"0.8\",\n",
      "    \"Reason\": \"Response accurately summarizes the steps to download payslips.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '0.8', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '0.8', 'Reason': 'Response accurately summarizes the steps to download payslips.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response accurately summarizes the steps to download payslips.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '0a3173ce-8a29-4638-bc17-e0a15abb60aa', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:18 GMT', 'content-type': 'application/json', 'content-length': '330', 'connection': 'keep-alive', 'x-amzn-requestid': '0a3173ce-8a29-4638-bc17-e0a15abb60aa', 'x-amzn-bedrock-invocation-latency': '972', 'x-amzn-bedrock-output-token-count': '60', 'x-amzn-bedrock-input-token-count': '309'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2e4a0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response matches ground truth and context.\\\"\\n}\",\"prompt_token_count\":309,\"generation_token_count\":60,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response matches ground truth and context.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response matches ground truth and context.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response matches ground truth and context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '0fa6df59-c2af-4df2-9dc3-d3fa1893c90d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:19 GMT', 'content-type': 'application/json', 'content-length': '349', 'connection': 'keep-alive', 'x-amzn-requestid': '0fa6df59-c2af-4df2-9dc3-d3fa1893c90d', 'x-amzn-bedrock-invocation-latency': '1084', 'x-amzn-bedrock-output-token-count': '69', 'x-amzn-bedrock-input-token-count': '314'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab346d0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"0.8\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"0.8\\\",\\n    \\\"Reason\\\": \\\"Response is mostly accurate, but with minor deviations.\\\"\\n}\",\"prompt_token_count\":314,\"generation_token_count\":69,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"0.8\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"0.8\",\n",
      "    \"Reason\": \"Response is mostly accurate, but with minor deviations.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '0.8', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '0.8', 'Reason': 'Response is mostly accurate, but with minor deviations.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response is mostly accurate, but with minor deviations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'a6f69d85-3488-4e84-97c3-d4877d3c6a3b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:21 GMT', 'content-type': 'application/json', 'content-length': '365', 'connection': 'keep-alive', 'x-amzn-requestid': 'a6f69d85-3488-4e84-97c3-d4877d3c6a3b', 'x-amzn-bedrock-invocation-latency': '1141', 'x-amzn-bedrock-output-token-count': '69', 'x-amzn-bedrock-input-token-count': '510'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab36350>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"0.8\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"0.8\\\",\\n    \\\"Reason\\\": \\\"Response accurately answers the question, but lacks some context details.\\\"\\n}\",\"prompt_token_count\":510,\"generation_token_count\":69,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"0.8\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"0.8\",\n",
      "    \"Reason\": \"Response accurately answers the question, but lacks some context details.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '0.8', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '0.8', 'Reason': 'Response accurately answers the question, but lacks some context details.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response accurately answers the question, but lacks some context details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '39b5e24a-c3fc-4331-b165-18764a80e65a', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:22 GMT', 'content-type': 'application/json', 'content-length': '332', 'connection': 'keep-alive', 'x-amzn-requestid': '39b5e24a-c3fc-4331-b165-18764a80e65a', 'x-amzn-bedrock-invocation-latency': '991', 'x-amzn-bedrock-output-token-count': '61', 'x-amzn-bedrock-input-token-count': '362'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2ed70>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Perfect match with ground truth and context.\\\"\\n}\",\"prompt_token_count\":362,\"generation_token_count\":61,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Perfect match with ground truth and context.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Perfect match with ground truth and context.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Perfect match with ground truth and context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'ea904457-411a-4e73-b73f-19d0f0f63ab2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:23 GMT', 'content-type': 'application/json', 'content-length': '335', 'connection': 'keep-alive', 'x-amzn-requestid': 'ea904457-411a-4e73-b73f-19d0f0f63ab2', 'x-amzn-bedrock-invocation-latency': '1065', 'x-amzn-bedrock-output-token-count': '68', 'x-amzn-bedrock-input-token-count': '279'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab46bf0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": 0.8,\\n    \\\"Context_precision\\\": 1,\\n    \\\"Answer_correctness\\\": 0.9,\\n    \\\"Answer_relevancy\\\": 1,\\n    \\\"Context_recall\\\": 1,\\n    \\\"Reason\\\": \\\"Minor differences in wording, but overall faithful and correct.\\\"\\n}\",\"prompt_token_count\":279,\"generation_token_count\":68,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": 0.8,\n",
      "    \"Context_precision\": 1,\n",
      "    \"Answer_correctness\": 0.9,\n",
      "    \"Answer_relevancy\": 1,\n",
      "    \"Context_recall\": 1,\n",
      "    \"Reason\": \"Minor differences in wording, but overall faithful and correct.\"\n",
      "}\n",
      "{'Faithfulness': 0.8, 'Context_precision': 1, 'Answer_correctness': 0.9, 'Answer_relevancy': 1, 'Context_recall': 1, 'Reason': 'Minor differences in wording, but overall faithful and correct.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "0.9\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Minor differences in wording, but overall faithful and correct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'df1913e8-7343-4432-83cb-c2a4d7120527', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:24 GMT', 'content-type': 'application/json', 'content-length': '330', 'connection': 'keep-alive', 'x-amzn-requestid': 'df1913e8-7343-4432-83cb-c2a4d7120527', 'x-amzn-bedrock-invocation-latency': '927', 'x-amzn-bedrock-output-token-count': '59', 'x-amzn-bedrock-input-token-count': '241'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2e350>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"0\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response acknowledges lack of information.\\\"\\n}\",\"prompt_token_count\":241,\"generation_token_count\":59,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"0\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response acknowledges lack of information.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '0', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response acknowledges lack of information.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "0\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response acknowledges lack of information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'c1413207-3b35-4af4-bd33-52380dfc3c1e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:25 GMT', 'content-type': 'application/json', 'content-length': '375', 'connection': 'keep-alive', 'x-amzn-requestid': 'c1413207-3b35-4af4-bd33-52380dfc3c1e', 'x-amzn-bedrock-invocation-latency': '1250', 'x-amzn-bedrock-output-token-count': '77', 'x-amzn-bedrock-input-token-count': '397'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2e440>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"1.0\\\",\\n    \\\"Answer_correctness\\\": \\\"0.75\\\",\\n    \\\"Answer_relevancy\\\": \\\"1.0\\\",\\n    \\\"Context_recall\\\": \\\"1.0\\\",\\n    \\\"Reason\\\": \\\"Response accurately summarizes leave types, but misorders and omits details.\\\"\\n}\",\"prompt_token_count\":397,\"generation_token_count\":77,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"1.0\",\n",
      "    \"Answer_correctness\": \"0.75\",\n",
      "    \"Answer_relevancy\": \"1.0\",\n",
      "    \"Context_recall\": \"1.0\",\n",
      "    \"Reason\": \"Response accurately summarizes leave types, but misorders and omits details.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '1.0', 'Answer_correctness': '0.75', 'Answer_relevancy': '1.0', 'Context_recall': '1.0', 'Reason': 'Response accurately summarizes leave types, but misorders and omits details.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "1.0\n",
      "answer_correctness\n",
      "0.75\n",
      "answer_relevancy\n",
      "1.0\n",
      "context_recall\n",
      "1.0\n",
      "reason\n",
      "Response accurately summarizes leave types, but misorders and omits details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '1b614de9-37d3-45ba-987e-7af4b7bf82fa', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:26 GMT', 'content-type': 'application/json', 'content-length': '360', 'connection': 'keep-alive', 'x-amzn-requestid': '1b614de9-37d3-45ba-987e-7af4b7bf82fa', 'x-amzn-bedrock-invocation-latency': '1090', 'x-amzn-bedrock-output-token-count': '69', 'x-amzn-bedrock-input-token-count': '261'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab45ae0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"0.9\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response is similar to ground truth, with minor wording differences.\\\"\\n}\",\"prompt_token_count\":261,\"generation_token_count\":69,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"0.9\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response is similar to ground truth, with minor wording differences.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '1', 'Answer_correctness': '0.9', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response is similar to ground truth, with minor wording differences.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "0.9\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response is similar to ground truth, with minor wording differences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '89304ede-cdf5-4a5b-be13-7b13efea50bb', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:27 GMT', 'content-type': 'application/json', 'content-length': '347', 'connection': 'keep-alive', 'x-amzn-requestid': '89304ede-cdf5-4a5b-be13-7b13efea50bb', 'x-amzn-bedrock-invocation-latency': '1039', 'x-amzn-bedrock-output-token-count': '65', 'x-amzn-bedrock-input-token-count': '277'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab37040>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response is mostly faithful, but adds unnecessary phrase.\\\"\\n}\",\"prompt_token_count\":277,\"generation_token_count\":65,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response is mostly faithful, but adds unnecessary phrase.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response is mostly faithful, but adds unnecessary phrase.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response is mostly faithful, but adds unnecessary phrase.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '84d70f35-f3d0-4500-86f5-6ebae14c4d0b', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:28 GMT', 'content-type': 'application/json', 'content-length': '335', 'connection': 'keep-alive', 'x-amzn-requestid': '84d70f35-f3d0-4500-86f5-6ebae14c4d0b', 'x-amzn-bedrock-invocation-latency': '1015', 'x-amzn-bedrock-output-token-count': '61', 'x-amzn-bedrock-input-token-count': '400'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab363e0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response accurately summarizes the POSH policy.\\\"\\n}\",\"prompt_token_count\":400,\"generation_token_count\":61,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response accurately summarizes the POSH policy.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response accurately summarizes the POSH policy.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response accurately summarizes the POSH policy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '26328389-a2ce-4a92-a6ec-665f1afc5294', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:30 GMT', 'content-type': 'application/json', 'content-length': '345', 'connection': 'keep-alive', 'x-amzn-requestid': '26328389-a2ce-4a92-a6ec-665f1afc5294', 'x-amzn-bedrock-invocation-latency': '1143', 'x-amzn-bedrock-output-token-count': '70', 'x-amzn-bedrock-input-token-count': '420'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2fc70>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"0.8\\\",\\n    \\\"Answer_correctness\\\": \\\"0.8\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"0.8\\\",\\n    \\\"Reason\\\": \\\"Response mostly accurate, but lacks some details.\\\"\\n}\",\"prompt_token_count\":420,\"generation_token_count\":70,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"0.8\",\n",
      "    \"Answer_correctness\": \"0.8\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"0.8\",\n",
      "    \"Reason\": \"Response mostly accurate, but lacks some details.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '0.8', 'Answer_correctness': '0.8', 'Answer_relevancy': '1', 'Context_recall': '0.8', 'Reason': 'Response mostly accurate, but lacks some details.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "0.8\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response mostly accurate, but lacks some details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'd938c42c-c41c-46f2-aea7-2ec3c0da4320', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:31 GMT', 'content-type': 'application/json', 'content-length': '361', 'connection': 'keep-alive', 'x-amzn-requestid': 'd938c42c-c41c-46f2-aea7-2ec3c0da4320', 'x-amzn-bedrock-invocation-latency': '1034', 'x-amzn-bedrock-output-token-count': '64', 'x-amzn-bedrock-input-token-count': '374'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab1e2f0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response accurately summarizes the Buddy Program's purpose and functions.\\\"\\n}\",\"prompt_token_count\":374,\"generation_token_count\":64,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response accurately summarizes the Buddy Program's purpose and functions.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': \"Response accurately summarizes the Buddy Program's purpose and functions.\"}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response accurately summarizes the Buddy Program's purpose and functions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '6cd5d8cd-c96e-4411-b9f7-a7a3285d9c85', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:32 GMT', 'content-type': 'application/json', 'content-length': '347', 'connection': 'keep-alive', 'x-amzn-requestid': '6cd5d8cd-c96e-4411-b9f7-a7a3285d9c85', 'x-amzn-bedrock-invocation-latency': '1180', 'x-amzn-bedrock-output-token-count': '75', 'x-amzn-bedrock-input-token-count': '310'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab1ece0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": 0.8,\\n    \\\"Context_precision\\\": 0.8,\\n    \\\"Answer_correctness\\\": 0.8,\\n    \\\"Answer_relevancy\\\": 1,\\n    \\\"Context_recall\\\": 0.8,\\n    \\\"Reason\\\": \\\"Response is mostly accurate, but lacks company name and has extra info.\\\"\\n}\",\"prompt_token_count\":310,\"generation_token_count\":75,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": 0.8,\n",
      "    \"Context_precision\": 0.8,\n",
      "    \"Answer_correctness\": 0.8,\n",
      "    \"Answer_relevancy\": 1,\n",
      "    \"Context_recall\": 0.8,\n",
      "    \"Reason\": \"Response is mostly accurate, but lacks company name and has extra info.\"\n",
      "}\n",
      "{'Faithfulness': 0.8, 'Context_precision': 0.8, 'Answer_correctness': 0.8, 'Answer_relevancy': 1, 'Context_recall': 0.8, 'Reason': 'Response is mostly accurate, but lacks company name and has extra info.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "0.8\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response is mostly accurate, but lacks company name and has extra info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'bc7df794-4862-4354-ac97-8f69301119f8', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:33 GMT', 'content-type': 'application/json', 'content-length': '367', 'connection': 'keep-alive', 'x-amzn-requestid': 'bc7df794-4862-4354-ac97-8f69301119f8', 'x-amzn-bedrock-invocation-latency': '1213', 'x-amzn-bedrock-output-token-count': '75', 'x-amzn-bedrock-input-token-count': '407'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab1e740>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"0.8\\\",\\n    \\\"Answer_correctness\\\": \\\"0.8\\\",\\n    \\\"Answer_relevancy\\\": \\\"0.8\\\",\\n    \\\"Context_recall\\\": \\\"0.6\\\",\\n    \\\"Reason\\\": \\\"Response is partially correct and relevant, but lacks explicit terms.\\\"\\n}\",\"prompt_token_count\":407,\"generation_token_count\":75,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"0.8\",\n",
      "    \"Answer_correctness\": \"0.8\",\n",
      "    \"Answer_relevancy\": \"0.8\",\n",
      "    \"Context_recall\": \"0.6\",\n",
      "    \"Reason\": \"Response is partially correct and relevant, but lacks explicit terms.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '0.8', 'Answer_correctness': '0.8', 'Answer_relevancy': '0.8', 'Context_recall': '0.6', 'Reason': 'Response is partially correct and relevant, but lacks explicit terms.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.8\n",
      "answer_correctness\n",
      "0.8\n",
      "answer_relevancy\n",
      "0.8\n",
      "context_recall\n",
      "0.6\n",
      "reason\n",
      "Response is partially correct and relevant, but lacks explicit terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'ed09be82-41fe-4e14-a307-24c81b41adc4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:34 GMT', 'content-type': 'application/json', 'content-length': '364', 'connection': 'keep-alive', 'x-amzn-requestid': 'ed09be82-41fe-4e14-a307-24c81b41adc4', 'x-amzn-bedrock-invocation-latency': '1215', 'x-amzn-bedrock-output-token-count': '73', 'x-amzn-bedrock-input-token-count': '554'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab1e350>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0.8\\\",\\n    \\\"Context_precision\\\": \\\"0.6\\\",\\n    \\\"Answer_correctness\\\": \\\"0.4\\\",\\n    \\\"Answer_relevancy\\\": \\\"0.8\\\",\\n    \\\"Context_recall\\\": \\\"0.8\\\",\\n    \\\"Reason\\\": \\\"Response includes some correct context but adds incorrect details.\\\"\\n}\",\"prompt_token_count\":554,\"generation_token_count\":73,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0.8\",\n",
      "    \"Context_precision\": \"0.6\",\n",
      "    \"Answer_correctness\": \"0.4\",\n",
      "    \"Answer_relevancy\": \"0.8\",\n",
      "    \"Context_recall\": \"0.8\",\n",
      "    \"Reason\": \"Response includes some correct context but adds incorrect details.\"\n",
      "}\n",
      "{'Faithfulness': '0.8', 'Context_precision': '0.6', 'Answer_correctness': '0.4', 'Answer_relevancy': '0.8', 'Context_recall': '0.8', 'Reason': 'Response includes some correct context but adds incorrect details.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "0.6\n",
      "answer_correctness\n",
      "0.4\n",
      "answer_relevancy\n",
      "0.8\n",
      "context_recall\n",
      "0.8\n",
      "reason\n",
      "Response includes some correct context but adds incorrect details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '95e91357-4362-4997-942d-202b83943db3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:36 GMT', 'content-type': 'application/json', 'content-length': '354', 'connection': 'keep-alive', 'x-amzn-requestid': '95e91357-4362-4997-942d-202b83943db3', 'x-amzn-bedrock-invocation-latency': '1075', 'x-amzn-bedrock-output-token-count': '64', 'x-amzn-bedrock-input-token-count': '596'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab517e0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0\\\",\\n    \\\"Context_precision\\\": \\\"0\\\",\\n    \\\"Answer_correctness\\\": \\\"0\\\",\\n    \\\"Answer_relevancy\\\": \\\"0\\\",\\n    \\\"Context_recall\\\": \\\"0\\\",\\n    \\\"Reason\\\": \\\"Response is unrelated to the question about maternal leave policy.\\\"\\n}\",\"prompt_token_count\":596,\"generation_token_count\":64,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0\",\n",
      "    \"Context_precision\": \"0\",\n",
      "    \"Answer_correctness\": \"0\",\n",
      "    \"Answer_relevancy\": \"0\",\n",
      "    \"Context_recall\": \"0\",\n",
      "    \"Reason\": \"Response is unrelated to the question about maternal leave policy.\"\n",
      "}\n",
      "{'Faithfulness': '0', 'Context_precision': '0', 'Answer_correctness': '0', 'Answer_relevancy': '0', 'Context_recall': '0', 'Reason': 'Response is unrelated to the question about maternal leave policy.'}\n",
      "faithfulness\n",
      "0\n",
      "context_precision\n",
      "0\n",
      "answer_correctness\n",
      "0\n",
      "answer_relevancy\n",
      "0\n",
      "context_recall\n",
      "0\n",
      "reason\n",
      "Response is unrelated to the question about maternal leave policy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': '8d2da900-dd7c-4c1b-ba4f-acbc9c9fba49', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:37 GMT', 'content-type': 'application/json', 'content-length': '351', 'connection': 'keep-alive', 'x-amzn-requestid': '8d2da900-dd7c-4c1b-ba4f-acbc9c9fba49', 'x-amzn-bedrock-invocation-latency': '992', 'x-amzn-bedrock-output-token-count': '63', 'x-amzn-bedrock-input-token-count': '228'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab34190>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"0\\\",\\n    \\\"Context_precision\\\": \\\"0\\\",\\n    \\\"Answer_correctness\\\": \\\"0\\\",\\n    \\\"Answer_relevancy\\\": \\\"0\\\",\\n    \\\"Context_recall\\\": \\\"0\\\",\\n    \\\"Reason\\\": \\\"Response does not match the expected greeting and introduction.\\\"\\n}\",\"prompt_token_count\":228,\"generation_token_count\":63,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"0\",\n",
      "    \"Context_precision\": \"0\",\n",
      "    \"Answer_correctness\": \"0\",\n",
      "    \"Answer_relevancy\": \"0\",\n",
      "    \"Context_recall\": \"0\",\n",
      "    \"Reason\": \"Response does not match the expected greeting and introduction.\"\n",
      "}\n",
      "{'Faithfulness': '0', 'Context_precision': '0', 'Answer_correctness': '0', 'Answer_relevancy': '0', 'Context_recall': '0', 'Reason': 'Response does not match the expected greeting and introduction.'}\n",
      "faithfulness\n",
      "0\n",
      "context_precision\n",
      "0\n",
      "answer_correctness\n",
      "0\n",
      "answer_relevancy\n",
      "0\n",
      "context_recall\n",
      "0\n",
      "reason\n",
      "Response does not match the expected greeting and introduction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'ef662645-3447-4226-a7db-15936211dc88', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:38 GMT', 'content-type': 'application/json', 'content-length': '348', 'connection': 'keep-alive', 'x-amzn-requestid': 'ef662645-3447-4226-a7db-15936211dc88', 'x-amzn-bedrock-invocation-latency': '993', 'x-amzn-bedrock-output-token-count': '61', 'x-amzn-bedrock-input-token-count': '369'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2dd80>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": \\\"1\\\",\\n    \\\"Context_precision\\\": \\\"1\\\",\\n    \\\"Answer_correctness\\\": \\\"1\\\",\\n    \\\"Answer_relevancy\\\": \\\"1\\\",\\n    \\\"Context_recall\\\": \\\"1\\\",\\n    \\\"Reason\\\": \\\"Response accurately summarizes the travel policy guidelines.\\\"\\n}\",\"prompt_token_count\":369,\"generation_token_count\":61,\"stop_reason\":\"stop\"}\n",
      "INFO:app:LLM request received\n",
      "INFO:app:LLM Call 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": \"1\",\n",
      "    \"Context_precision\": \"1\",\n",
      "    \"Answer_correctness\": \"1\",\n",
      "    \"Answer_relevancy\": \"1\",\n",
      "    \"Context_recall\": \"1\",\n",
      "    \"Reason\": \"Response accurately summarizes the travel policy guidelines.\"\n",
      "}\n",
      "{'Faithfulness': '1', 'Context_precision': '1', 'Answer_correctness': '1', 'Answer_relevancy': '1', 'Context_recall': '1', 'Reason': 'Response accurately summarizes the travel policy guidelines.'}\n",
      "faithfulness\n",
      "1\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "1\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Response accurately summarizes the travel policy guidelines.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:app:Raw Response: {'ResponseMetadata': {'RequestId': 'b386288e-8cc0-48f7-b30f-a047e74ddb1d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Thu, 26 Sep 2024 11:14:39 GMT', 'content-type': 'application/json', 'content-length': '346', 'connection': 'keep-alive', 'x-amzn-requestid': 'b386288e-8cc0-48f7-b30f-a047e74ddb1d', 'x-amzn-bedrock-invocation-latency': '1112', 'x-amzn-bedrock-output-token-count': '68', 'x-amzn-bedrock-input-token-count': '388'}, 'RetryAttempts': 0}, 'contentType': 'application/json', 'body': <botocore.response.StreamingBody object at 0xf602cab2eec0>}\n",
      "INFO:app:Response Data: {\"generation\":\"\\n\\n{\\n    \\\"Faithfulness\\\": 0.8,\\n    \\\"Context_precision\\\": 1,\\n    \\\"Answer_correctness\\\": 0,\\n    \\\"Answer_relevancy\\\": 1,\\n    \\\"Context_recall\\\": 1,\\n    \\\"Reason\\\": \\\"Incorrect calculation of total leaves, but relevant and faithful to context.\\\"\\n}\",\"prompt_token_count\":388,\"generation_token_count\":68,\"stop_reason\":\"stop\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "{\n",
      "    \"Faithfulness\": 0.8,\n",
      "    \"Context_precision\": 1,\n",
      "    \"Answer_correctness\": 0,\n",
      "    \"Answer_relevancy\": 1,\n",
      "    \"Context_recall\": 1,\n",
      "    \"Reason\": \"Incorrect calculation of total leaves, but relevant and faithful to context.\"\n",
      "}\n",
      "{'Faithfulness': 0.8, 'Context_precision': 1, 'Answer_correctness': 0, 'Answer_relevancy': 1, 'Context_recall': 1, 'Reason': 'Incorrect calculation of total leaves, but relevant and faithful to context.'}\n",
      "faithfulness\n",
      "0.8\n",
      "context_precision\n",
      "1\n",
      "answer_correctness\n",
      "0\n",
      "answer_relevancy\n",
      "1\n",
      "context_recall\n",
      "1\n",
      "reason\n",
      "Incorrect calculation of total leaves, but relevant and faithful to context.\n",
      "                                               conv_id  msg_id  \\\n",
      "0                                                  123       1   \n",
      "1                                               123456       1   \n",
      "2                                               123456       3   \n",
      "3                                               123456       7   \n",
      "4                                               123456       9   \n",
      "16   19:3f83b80d-b01e-4077-9fdc-26fbc91dc439_5cec54...       1   \n",
      "20                                                 565       1   \n",
      "50                                                5656       9   \n",
      "71   a:1Ame40W8-C6EjVgnf4XrTG0BC3qer51B4GVmqa0kwS-p...       1   \n",
      "72   a:1F6h57q4wG3bftUT4K97xlqqKD4_BVQqc4s2JAheRJxj...       1   \n",
      "100  a:1vz_gh-aOO2D7zfNgtpVUuCaXQ-3bp5LL5KGHG63DQE1...       3   \n",
      "108  a:1vz_gh-aOO2D7zfNgtpVUuCaXQ-3bp5LL5KGHG63DQE1...      20   \n",
      "114  a:1vz_gh-aOO2D7zfNgtpVUuCaXQ-3bp5LL5KGHG63DQE1...      30   \n",
      "120  a:1xtpApCxIbCrioG_Gh-le2NdReq2o4uufjlTK0Eekp64...      19   \n",
      "124                                                abc       1   \n",
      "125                                                abc       2   \n",
      "128                                                abc       2   \n",
      "133                                                abc      10   \n",
      "144                                                abc      30   \n",
      "157                                               abcd       1   \n",
      "\n",
      "                       time  \\\n",
      "0   2024-09-13 12:10:20.383   \n",
      "1   2024-09-11 08:15:14.595   \n",
      "2   2024-09-11 08:17:17.677   \n",
      "3   2024-09-11 08:29:24.793   \n",
      "4   2024-09-11 08:45:29.847   \n",
      "16  2024-09-09 10:10:54.609   \n",
      "20  2024-09-24 06:30:46.747   \n",
      "50  2024-09-25 16:36:53.229   \n",
      "71  2024-09-18 05:37:43.669   \n",
      "72  2024-09-13 09:08:27.974   \n",
      "100 2024-09-10 04:47:12.650   \n",
      "108 2024-09-13 06:04:54.728   \n",
      "114 2024-09-16 10:17:11.336   \n",
      "120 2024-09-17 09:55:06.394   \n",
      "124 2024-09-09 10:07:50.657   \n",
      "125 2024-09-09 10:35:51.010   \n",
      "128 2024-09-09 12:48:57.709   \n",
      "133 2024-09-10 07:28:11.744   \n",
      "144 2024-09-11 14:48:13.215   \n",
      "157 2024-09-09 10:14:32.849   \n",
      "\n",
      "                                                 query  \\\n",
      "0          What are the steps to download my payslips?   \n",
      "1    Who is responsible for overseeing the smooth t...   \n",
      "2    Who is responsible for reporting a power outag...   \n",
      "3    Can sabotage or vandalism to building, compute...   \n",
      "4    Who should be immediately notified in case of ...   \n",
      "16               <at>jinie by gemini-dev</at> hi jinie   \n",
      "20      How many leaves are there in gemini solutions?   \n",
      "50      How many leaves are there in gemini solutions?   \n",
      "71                                            hi jinie   \n",
      "72                                                  hi   \n",
      "100               what is the posh harassment policy ?   \n",
      "108               what is the maternity leave policy ?   \n",
      "114                        what is the buddy program ?   \n",
      "120                                             pluxee   \n",
      "124  What are the terms on which it depends how muc...   \n",
      "125  What are the terms on which it depends how muc...   \n",
      "128                 What is the maternal leave policy?   \n",
      "133                                           Hi Jinie   \n",
      "144                                 What about travel?   \n",
      "157             How many leaves can we take in a year.   \n",
      "\n",
      "                                       rewritten_query  \\\n",
      "0          What are the steps to download my payslips?   \n",
      "1    Who is responsible for overseeing the smooth t...   \n",
      "2    Who is responsible for reporting a power outag...   \n",
      "3    Can sabotage or vandalism to building, compute...   \n",
      "4    Who should be immediately notified in case of ...   \n",
      "16               <at>jinie by gemini-dev</at> hi jinie   \n",
      "20      How many leaves are there in gemini solutions?   \n",
      "50   What types of leaves are mentioned in Gemini S...   \n",
      "71                                            hi jinie   \n",
      "72                                                  hi   \n",
      "100               what is the posh harassment policy ?   \n",
      "108               what is the maternity leave policy ?   \n",
      "114                        what is the buddy program ?   \n",
      "120             what is pluxee or how does pluxee work   \n",
      "124  What are the terms on which it depends how muc...   \n",
      "125  What are the terms on which it depends how muc...   \n",
      "128                 What is the maternal leave policy?   \n",
      "133                                           Hi Jinie   \n",
      "144                                 What about travel?   \n",
      "157             How many leaves can we take in a year.   \n",
      "\n",
      "                                              response  \\\n",
      "0    To download your payslips, log in to your Grey...   \n",
      "1    The BC/DR Leader is responsible for overseeing...   \n",
      "2    In case of a power outage during off-office ho...   \n",
      "3    Yes, sabotage or vandalism to building, comput...   \n",
      "4    In case of loss or theft of equipment or data,...   \n",
      "16   Hi! I'm Jinie, the HR policy bot for Gemini So...   \n",
      "20                                                       \n",
      "50   According to Gemini Solutions' Leave Policy Ve...   \n",
      "71   Hello! I'm Jinie, the HR policy bot for Gemini...   \n",
      "72   Hello! I'm Jinie, the HR policy bot for Gemini...   \n",
      "100                                                      \n",
      "108                                                      \n",
      "114                                                      \n",
      "120  Pluxee is a food wallet credited with INR 2000...   \n",
      "124                                                      \n",
      "125  The terms on which the appraisal amount depend...   \n",
      "128  The terms on which the appraisal amount depend...   \n",
      "133                                                      \n",
      "144                                                      \n",
      "157  As per the company's leave policy, each year y...   \n",
      "\n",
      "                                              metadata  \\\n",
      "0    {'conversation_id': '123', 'query': 'What are ...   \n",
      "1    {'conversation_id': '123456', 'query': 'Who is...   \n",
      "2    {'conversation_id': '123456', 'query': 'Who is...   \n",
      "3    {'conversation_id': '123456', 'query': 'Can sa...   \n",
      "4    {'conversation_id': '123456', 'query': 'Who sh...   \n",
      "16   {'conversation_id': '19:3f83b80d-b01e-4077-9fd...   \n",
      "20                                                 NaN   \n",
      "50   {'conversation_id': '5656', 'query': \"What typ...   \n",
      "71   {'conversation_id': 'a:1Ame40W8-C6EjVgnf4XrTG0...   \n",
      "72   {'conversation_id': 'a:1F6h57q4wG3bftUT4K97xlq...   \n",
      "100                                                NaN   \n",
      "108                                                NaN   \n",
      "114                                                NaN   \n",
      "120  {'conversation_id': 'a:1xtpApCxIbCrioG_Gh-le2N...   \n",
      "124                                                NaN   \n",
      "125  {'conversation_id': 'abc', 'query': 'What are ...   \n",
      "128  {'conversation_id': 'abc', 'query': 'What are ...   \n",
      "133                                                NaN   \n",
      "144                                                NaN   \n",
      "157  {'conversation_id': 'abcd', 'query': 'How many...   \n",
      "\n",
      "                                             reference  sentiment  \\\n",
      "0    [{'Statement': 'You can log in to your GreytHR...   0.000000   \n",
      "1    [{'Statement': 'To oversee the smooth transiti...   0.083333   \n",
      "2    [{'Statement': 'Concerned person checks the po...   0.200000   \n",
      "3    [{'Statement': 'All employees frisked at the t...   0.083333   \n",
      "4    [{'Statement': 'Immediately report the inciden...   0.000000   \n",
      "16                                                  []   0.000000   \n",
      "20                                                 NaN   0.500000   \n",
      "50   [{'Statement': 'Every confirmed employee will ...   0.500000   \n",
      "71                                                  []   0.000000   \n",
      "72                                                  []   0.000000   \n",
      "100                                                NaN   0.000000   \n",
      "108                                                NaN   0.000000   \n",
      "114                                                NaN   0.000000   \n",
      "120  [{'Statement': 'If you opt for it, INR 2000 wi...   0.000000   \n",
      "124                                                NaN   0.200000   \n",
      "125  [{'Statement': 'Employees who transfer after S...   0.200000   \n",
      "128  [{'Statement': 'Employees who transfer after S...   0.000000   \n",
      "133                                                NaN   0.000000   \n",
      "144                                                NaN   0.000000   \n",
      "157  [{'Statement': 'Each year, you’ll receive 7 Ca...   0.500000   \n",
      "\n",
      "                                 ground_truth_response  \\\n",
      "0    To download your payslips, follow these steps:...   \n",
      "1    The BC/DR Leader is responsible for overseeing...   \n",
      "2    In case of a power outage during off-office ho...   \n",
      "3    Yes, sabotage or vandalism to building, comput...   \n",
      "4    In case of loss or theft of equipment or data,...   \n",
      "16   Hi! I'm Jinie, your HR policy bot. I'm here to...   \n",
      "20   The number of leaves in Gemini Solutions is no...   \n",
      "50   The types of leaves mentioned in Gemini Soluti...   \n",
      "71   Hi! I'm Jinie, your HR policy bot. I'm here to...   \n",
      "72   Hello! I'm Jinie, the HR policy bot for Gemini...   \n",
      "100  The POSH (Prevention of Sexual Harassment) pol...   \n",
      "108  Gemini Solutions' maternity leave policy allow...   \n",
      "114  The Buddy Program is an integral part of the o...   \n",
      "120  Pluxee is a food wallet provided by Gemini Sol...   \n",
      "124  The terms on which the appraisal amount depend...   \n",
      "125  The terms on which the appraisal amount depend...   \n",
      "128  If you're a married female employee, you can e...   \n",
      "133  Hi! I'm Jinie, your HR policy bot. I'm here to...   \n",
      "144  Gemini Solutions has a travel policy in place ...   \n",
      "157  Each year, you'll receive 7 Casual Leaves (CLs...   \n",
      "\n",
      "                                 ground_truth_metadata  \\\n",
      "0    {'conversation_id': 'None', 'query': 'What are...   \n",
      "1    {'conversation_id': 'None', 'query': 'Who is r...   \n",
      "2    {'conversation_id': 'None', 'query': 'Who is r...   \n",
      "3    {'conversation_id': 'None', 'query': 'Can sabo...   \n",
      "4    {'conversation_id': 'None', 'query': 'Who shou...   \n",
      "16   {'conversation_id': 'None', 'query': '<at>jini...   \n",
      "20   {'conversation_id': 'None', 'query': 'How many...   \n",
      "50   {'conversation_id': 'None', 'query': 'What typ...   \n",
      "71   {'conversation_id': 'None', 'query': 'hi jinie...   \n",
      "72   {'conversation_id': 'None', 'query': 'hi', 'so...   \n",
      "100  {'conversation_id': 'None', 'query': 'what is ...   \n",
      "108  {'conversation_id': 'None', 'query': 'what is ...   \n",
      "114  {'conversation_id': 'None', 'query': 'what is ...   \n",
      "120  {'conversation_id': 'None', 'query': 'what is ...   \n",
      "124  {'conversation_id': 'None', 'query': 'What are...   \n",
      "125  {'conversation_id': 'None', 'query': 'What are...   \n",
      "128  {'conversation_id': 'None', 'query': 'What is ...   \n",
      "133  {'conversation_id': 'None', 'query': 'Hi Jinie...   \n",
      "144  {'conversation_id': 'None', 'query': 'What abo...   \n",
      "157  {'conversation_id': 'None', 'query': 'How many...   \n",
      "\n",
      "                                ground_truth_reference  response_accuracy  \\\n",
      "0    [{'Statement': 'You can log in to your GreytHR...                0.5   \n",
      "1    [{'Statement': 'To oversee the smooth transiti...                1.0   \n",
      "2    [{'Statement': 'During off office hours, Conce...                0.5   \n",
      "3    [{'Statement': 'Background checks are performe...                0.5   \n",
      "4    [{'Statement': 'In case of Laptop immediately ...                0.5   \n",
      "16                                                  []                0.5   \n",
      "20                                                  []                0.0   \n",
      "50   [{'Statement': '5. Types of Leaves', 'source':...                0.5   \n",
      "71                                                  []                0.5   \n",
      "72                                                  []                0.5   \n",
      "100  [{'Statement': 'The policy is intended to ensu...                0.0   \n",
      "108  [{'Statement': 'If you're a married female emp...                0.0   \n",
      "114  [{'Statement': '5.1 The Buddy Program is an in...                0.0   \n",
      "120  [{'Statement': 'If you opt for it, INR 2000 wi...                0.5   \n",
      "124  [{'Statement': 'The appraisal cycle runs from ...                0.0   \n",
      "125  [{'Statement': 'The appraisal cycle runs from ...                0.5   \n",
      "128  [{'Statement': 'If you're a married female emp...                0.5   \n",
      "133                                                 []                0.0   \n",
      "144  [{'Statement': 'Your trip must be booked at le...                0.0   \n",
      "157  [{'Statement': 'Each year, you’ll receive 7 Ca...                0.5   \n",
      "\n",
      "    faithfulness context_precision answer_correctness answer_relevancy  \\\n",
      "0            0.8               0.8                  1                1   \n",
      "1              1                 1                  1                1   \n",
      "2            0.8               0.8                  1                1   \n",
      "3              1               0.8                  1                1   \n",
      "4              1                 1                  1                1   \n",
      "16           0.8                 1                0.9                1   \n",
      "20             1                 1                  0                1   \n",
      "50           0.8               1.0               0.75              1.0   \n",
      "71           0.8                 1                0.9                1   \n",
      "72           0.8                 1                  1                1   \n",
      "100            1                 1                  1                1   \n",
      "108          0.8               0.8                0.8                1   \n",
      "114            1                 1                  1                1   \n",
      "120          0.8               0.8                0.8                1   \n",
      "124          0.8               0.8                0.8              0.8   \n",
      "125          0.8               0.6                0.4              0.8   \n",
      "128            0                 0                  0                0   \n",
      "133            0                 0                  0                0   \n",
      "144            1                 1                  1                1   \n",
      "157          0.8                 1                  0                1   \n",
      "\n",
      "    context_recall                                             reason  \n",
      "0              0.8  Response accurately summarizes the steps to do...  \n",
      "1                1         Response matches ground truth and context.  \n",
      "2              0.8  Response is mostly accurate, but with minor de...  \n",
      "3              0.8  Response accurately answers the question, but ...  \n",
      "4                1       Perfect match with ground truth and context.  \n",
      "16               1  Minor differences in wording, but overall fait...  \n",
      "20               1         Response acknowledges lack of information.  \n",
      "50             1.0  Response accurately summarizes leave types, bu...  \n",
      "71               1  Response is similar to ground truth, with mino...  \n",
      "72               1  Response is mostly faithful, but adds unnecess...  \n",
      "100              1    Response accurately summarizes the POSH policy.  \n",
      "108            0.8  Response mostly accurate, but lacks some details.  \n",
      "114              1  Response accurately summarizes the Buddy Progr...  \n",
      "120            0.8  Response is mostly accurate, but lacks company...  \n",
      "124            0.6  Response is partially correct and relevant, bu...  \n",
      "125            0.8  Response includes some correct context but add...  \n",
      "128              0  Response is unrelated to the question about ma...  \n",
      "133              0  Response does not match the expected greeting ...  \n",
      "144              1  Response accurately summarizes the travel poli...  \n",
      "157              1  Incorrect calculation of total leaves, but rel...  \n",
      "Analysis successfully saved to analysis_report.xlsx\n"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    df.to_excel('conversation_data.xlsx', index=False)\n",
    "    print(f\"Data successfully saved to conversation_data.xlsx\")\n",
    "    conv = create_msg_dataset(df)\n",
    "    conv.to_excel('conv_history.xlsx', index=False)\n",
    "    print(f\"Data successfully saved to conv_history.xlsx\")\n",
    "analyze_history(db, file_name = 'conv_history.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
